{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatización del Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de parámetros del pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = ParameterString(name='DatasetPath', default_value=f's3://{bucket}/{datasets_prefix}')\n",
    "model_approval_status = ParameterString(name='ModelApprovalStatus', default_value='PendingManualApproval')  # \"Approved\" Si no se requiere aprobación manual\n",
    "minimum_precision = ParameterFloat(name='MinimumPrecision', default_value=0.85)\n",
    "\n",
    "parameters_list = [dataset_path, model_approval_status, minimum_precision]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar paso al pipeline para ejecutar Processing Job para la preparación del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_step_parameters = {\n",
    "    'name':'Preparacion-de-Datos',\n",
    "    'processor':processor}\n",
    "\n",
    "data_prep_step_parameters.update(data_prep_parameters)\n",
    "data_prep_step_parameters['job_arguments'] = data_prep_step_parameters.pop('arguments')\n",
    "\n",
    "data_prep_step_parameters['inputs']=[ProcessingInput(input_name='input',\n",
    "                                         source=dataset_path,\n",
    "                                         destination='/opt/ml/processing/input'),\n",
    "                                     ProcessingInput(input_name='code',\n",
    "                                         source=data_prep_script_path,\n",
    "                                         destination='/opt/ml/processing/input/code')]\n",
    "\n",
    "data_prep_step = ProcessingStep(**data_prep_step_parameters)\n",
    "pipeline_steps = [data_prep_step]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar paso al pipeline para entrenamiento de los modelos utilizando Training Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = {}\n",
    "for algorithm in estimators:       \n",
    "    training_steps[algorithm] = TrainingStep(\n",
    "        name=f'Entrenamiento-con-{algorithm}',\n",
    "        estimator=tuners[algorithm].best_estimator(),\n",
    "        inputs={\n",
    "            'train_data': TrainingInput(\n",
    "                data_prep_step.properties.ProcessingOutputConfig.Outputs['train_data'].S3Output.S3Uri),\n",
    "            'train_target': TrainingInput(\n",
    "                data_prep_step.properties.ProcessingOutputConfig.Outputs['train_target'].S3Output.S3Uri)})\n",
    "    \n",
    "    pipeline_steps.append(training_steps[algorithm])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar paso al pipeline para evaluación de desempeño de los modelos, utilizando un Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_files = {}\n",
    "\n",
    "for algorithm in estimators:\n",
    "    property_file = PropertyFile(\n",
    "        name=f'{algorithm}Metrics',\n",
    "        output_name=\"eval\",\n",
    "        path=f'{algorithm}_metrics.json')\n",
    "        \n",
    "    property_files[algorithm] = property_file\n",
    "\n",
    "eval_step_parameters = {\n",
    "    'name':'Evaluacion-de-modelos',\n",
    "    'processor':evaluation_processor,\n",
    "    'property_files':[property_files[file] for file in property_files]}\n",
    "\n",
    "eval_step_parameters.update(eval_parameters)\n",
    "eval_step_parameters['job_arguments'] = eval_step_parameters.pop('arguments')\n",
    "\n",
    "eval_step_parameters['inputs'] = [\n",
    "    ProcessingInput(\n",
    "        input_name='code',\n",
    "        source=evaluate_models_script_path,\n",
    "        destination='/opt/ml/processing/input/code'),\n",
    "    ProcessingInput(\n",
    "        source=data_prep_step.properties.ProcessingOutputConfig.Outputs['test_target'].S3Output.S3Uri, \n",
    "        destination='/opt/ml/processing/input/target'),\n",
    "    ProcessingInput(\n",
    "        source=data_prep_step.properties.ProcessingOutputConfig.Outputs['test_data'].S3Output.S3Uri, \n",
    "        destination='/opt/ml/processing/input/data'),\n",
    "    ProcessingInput(\n",
    "        source=training_steps['GradientBoosting'].properties.ModelArtifacts.S3ModelArtifacts, \n",
    "        destination='/opt/ml/processing/input/GradientBoosting'),\n",
    "    ProcessingInput(\n",
    "        source=training_steps['RandomForest'].properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        destination='/opt/ml/processing/input/RandomForest'),\n",
    "    ProcessingInput(\n",
    "        source=training_steps['ExtraTrees'].properties.ModelArtifacts.S3ModelArtifacts, \n",
    "        destination='/opt/ml/processing/input/ExtraTrees')]\n",
    "\n",
    "eval_step = ProcessingStep(**eval_step_parameters)\n",
    "pipeline_steps.append(eval_step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar condición para registrar modelo en el Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_group_name = f'{prefix}-PackageGroup'\n",
    "\n",
    "for algorithm in estimators:   \n",
    "    model_metrics = ModelMetrics(\n",
    "        model_statistics = MetricsSource(\n",
    "            s3_uri=\"{}/{}_metrics.json\".format(\n",
    "                eval_step.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"],\n",
    "                algorithm),\n",
    "            content_type=\"application/json\"))\n",
    "    \n",
    "    register_step = RegisterModel(\n",
    "        name=f\"Registra{algorithm}\",\n",
    "        estimator=estimators[algorithm],\n",
    "        model_data=training_steps[algorithm].properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        model_package_group_name=package_group_name,\n",
    "        approval_status=model_approval_status,\n",
    "        description=f'Churn prediction using {algorithm}',\n",
    "        model_metrics=model_metrics,\n",
    "        image_uri=docker_images['Inference']['image_uri'],\n",
    "        entry_point = training_script_file\n",
    "    )\n",
    "    \n",
    "    condition = ConditionGreaterThanOrEqualTo(\n",
    "        left = JsonGet(\n",
    "            step_name = 'Evaluacion-de-modelos',\n",
    "            property_file = property_files[algorithm],\n",
    "            json_path = f'binary_classification_metrics.precision.value'),\n",
    "        right = minimum_precision)\n",
    "    \n",
    "    condition_step = ConditionStep(\n",
    "        name=f\"{algorithm}Precision\",\n",
    "        conditions=[condition],\n",
    "        if_steps=[register_step],\n",
    "        else_steps=[])\n",
    "    \n",
    "    pipeline_steps.append(condition_step)\n",
    "    \n",
    "print(f'Package Group Name: {package_group_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esta celda deberia dar como resultado: Package Group Name: churn-clf-PackageGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecución del pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(name=f'{prefix}-pipeline-{strftime(\"%M-%S\", gmtime())}',\n",
    "                    parameters=parameters_list,\n",
    "                    steps=pipeline_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera definición del pipeline para ver que no exista ningún problema, si no arroja ningún error la ejecución de la siguiente celda, todo está bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition = json.loads(pipeline.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=sagemaker_role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
