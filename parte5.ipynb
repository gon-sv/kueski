{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker nos ofrece la funcionalidad de optimización de hiperpárametros, ya sea utilizando una búsqueda aleatoria o un método bayesiano, en este caso vamos a utilizar el segundo método el cual permite entrenar un modelo de forma iterativa e ir identificando que combinación de hiperparámetros, nos permite minimizar o maximizar más la métrica objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear proceso de optimización (Tuning Job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a que creamos tres estimators para el entrenamiento, ahora podemos crear tres procesos de optimización que se ejecuten en paralelo, para esto utilizamos la clase HyperparameterTuner y especificamos los rangos de valores para los hiperparámetros utilizando ContinuousParameter, IntegerParameter o CategoricalParameter dependiendo de si se trata de un valor continuo, discreto o categórico; respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuners = {}\n",
    "\n",
    "total_jobs = 16\n",
    "parallel_jobs = 2\n",
    "\n",
    "tuners['GradientBoosting'] = HyperparameterTuner(\n",
    "        estimator=estimators['GradientBoosting'],\n",
    "        objective_metric_name=metric_name,\n",
    "        objective_type='Maximize',\n",
    "        hyperparameter_ranges={'learning-rate': ContinuousParameter(0.01, 0.1),\n",
    "                                'min-samples-split': IntegerParameter(5, 15), \n",
    "                                'n-estimators': IntegerParameter(400, 800),\n",
    "                                'max-depth': IntegerParameter(3, 10),\n",
    "                                'max-features': IntegerParameter(15, 30)},\n",
    "        metric_definitions=[{'Name': metric_name, \n",
    "                             'Regex': metric_regex}],\n",
    "        max_jobs=total_jobs,\n",
    "        max_parallel_jobs=parallel_jobs)\n",
    "\n",
    "tuners['RandomForest'] = HyperparameterTuner(\n",
    "        estimator=estimators['RandomForest'],\n",
    "        objective_metric_name=metric_name,\n",
    "        objective_type='Maximize',\n",
    "        hyperparameter_ranges={'min-samples-split': IntegerParameter(3,10), \n",
    "                               'n-estimators': IntegerParameter(150,300),\n",
    "                               'max-depth': IntegerParameter(20,35),\n",
    "                               'max-features': IntegerParameter(15,30)},\n",
    "        metric_definitions=[{'Name': metric_name, \n",
    "                              'Regex': metric_regex}],\n",
    "        max_jobs=total_jobs,\n",
    "        max_parallel_jobs=parallel_jobs)\n",
    "\n",
    "tuners['ExtraTrees'] = HyperparameterTuner(\n",
    "        estimator=estimators['ExtraTrees'],\n",
    "        objective_metric_name=metric_name,\n",
    "        objective_type='Maximize',\n",
    "        hyperparameter_ranges={'min-samples-split': IntegerParameter(3,10), \n",
    "                               'n-estimators': IntegerParameter(150,350),\n",
    "                               'max-depth': IntegerParameter(20,35),\n",
    "                               'max-features': IntegerParameter(15,30)},\n",
    "        metric_definitions=[{'Name': metric_name, \n",
    "                              'Regex': metric_regex}],\n",
    "        max_jobs=total_jobs,\n",
    "        max_parallel_jobs=parallel_jobs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable total_jobs especifíca el número total de procesos de entrenamiento (combinaciones distintas de valores de hiperparámetros) a ejecutar y la variable parallel_jobs especifíca el número máximo de procesos a ejecutar en paralelo.\n",
    "\n",
    "Para ejecutar cada uno de los procesos utilizamos el método fit() pasando como parámetros la ubicación de los datasets y mediante el parámetro wait=False es que le indicamos que ejecute el proceso de manera asíncrona (sin esperar a que cada uno de los procesos termine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tuner in tuners:\n",
    "    tuners[tuner].fit({'train_data': sagemaker_utils.get_processor_output_path(processor, 'train_data'),\n",
    "                       'train_target': sagemaker_utils.get_processor_output_path(processor, 'train_target')}, \n",
    "                      job_name= f'{prefix}-{tuner}-{strftime(\"%M-%S\", gmtime())}',\n",
    "                      wait=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos un waiter\n",
    "\n",
    "sagemaker_utils.wait_for_optmimization_jobs(tuners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la invocación del método describe() podemos obtener el proceso de entrenamiento cuyo modelo resultante obtuvo el mejor desempeño, en este caso maximizando la métrica objetivo Recall. Posteriormente de los metadatos devueltos del mejor proceso de entrenamiento, podemos obtener los valores de los hiperparámetros así cómo el valor obtenido en la métrica objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {}\n",
    "for tuner in tuners:\n",
    "    best_training_job = tuners[tuner].describe()['BestTrainingJob']\n",
    "    objective_metric = best_training_job['FinalHyperParameterTuningJobObjectiveMetric']\n",
    "    \n",
    "    hyperparameters[tuner] = best_training_job['TunedHyperParameters']\n",
    "    print(tuner)\n",
    "    print(f\"\\thyper parameters: {hyperparameters[tuner]}\")\n",
    "    print(f\"\\t{objective_metric['MetricName']}: {objective_metric['Value']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos el mejor candidato (modelo con mejor desempeño) para cada uno de los tres algoritmos, podemos pasar a comparar el desempeño entre estos para seleccionar el mejor"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f087cbbaaafa03b885b484966f26ebaef7143783b0ae783847677076d63b434"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('drift_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
